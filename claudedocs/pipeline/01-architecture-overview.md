# ë°ì´í„° íŒŒì´í”„ë¼ì¸ ì•„í‚¤í…ì²˜ ê°œìš”

## ğŸ¯ í”„ë¡œì íŠ¸ ëª©ì 
**ì‹¤ì‹œê°„ CDC ê¸°ë°˜ ë°ì´í„° íŒŒì´í”„ë¼ì¸ êµ¬ì¶• ë° ê²€ì¦**
- MySQL í”Œë«í¼ ë°ì´í„°ë¥¼ ì‹¤ì‹œê°„ìœ¼ë¡œ ClickHouseì— ë™ê¸°í™”
- Flink CDC + Kafka + Flink Sync Connectorë¥¼ í™œìš©í•œ ìŠ¤íŠ¸ë¦¬ë° íŒŒì´í”„ë¼ì¸
- Docker Compose ê¸°ë°˜ ë¡œì»¬ í…ŒìŠ¤íŠ¸ í™˜ê²½ êµ¬ì„±

## ğŸ“Š ì „ì²´ ì•„í‚¤í…ì²˜

```mermaid
graph LR
    User[ğŸ‘¤ User<br/>HTML Form] --> NestJS[NestJS<br/>Platform Service]
    NestJS --> MySQL[(MySQL<br/>Source DB)]

    MySQL -->|binlog CDC| FlinkCDC[Apache Flink<br/>CDC Job]
    FlinkCDC -->|Change Events| Kafka[Confluent Kafka<br/>KRaft Mode]

    Kafka -->|Stream Data| FlinkSync[Apache Flink<br/>Sync Connector Job]
    FlinkSync --> ClickHouse[(ClickHouse<br/>Analytics DB)]

    ClickHouse --> Dashboard[ğŸ“Š Real-time<br/>Dashboard]

    style MySQL fill:#4479A1,color:#fff
    style Kafka fill:#231F20,color:#fff
    style ClickHouse fill:#FFCC00,color:#000
    style FlinkCDC fill:#E6526F,color:#fff
    style FlinkSync fill:#E6526F,color:#fff
    style NestJS fill:#E0234E,color:#fff
```

## ğŸ”„ ë°ì´í„° íë¦„ ìƒì„¸

### Phase 1: ë°ì´í„° ìƒì„± (Platform Service)
```
User Input (HTML Form)
    â†“
NestJS REST API (/api/orders)
    â†“
MySQL INSERT/UPDATE/DELETE
    â†“
MySQL Binlog ê¸°ë¡
```

### Phase 2: CDC ìº¡ì²˜ (Flink CDC)
```
MySQL Binlog Monitoring (Flink CDC)
    â†“
Change Event ê°ì§€ (INSERT/UPDATE/DELETE)
    â†“
Kafka Topicìœ¼ë¡œ ì „ì†¡ (orders-cdc-topic)
```

**Change Event êµ¬ì¡° (ì˜ˆì‹œ)**:
```json
{
  "before": null,
  "after": {
    "order_id": 1001,
    "user_id": 500,
    "product_name": "Laptop",
    "quantity": 2,
    "total_price": 2000.00,
    "status": "pending",
    "created_at": "2025-01-11T10:30:00Z"
  },
  "op": "c",  // c=create, u=update, d=delete
  "ts_ms": 1736592600000
}
```

### Phase 3: ë©”ì‹œì§€ íì‰ (Kafka)
```
Kafka Topic: orders-cdc-topic
    â†“
Partitions: 3 (í™•ì¥ì„± ê³ ë ¤)
    â†“
Retention: 7 days
    â†“
Consumer: Flink Sync Connector
```

### Phase 4: ClickHouse ë™ê¸°í™” (Flink Sync Connector)
```
Kafka Consumer (Flink Job)
    â†“
Data Transformation (í•„ìš” ì‹œ ìŠ¤í‚¤ë§ˆ ë³€í™˜)
    â†“
ClickHouse Batch Insert (Buffering)
    â†“
Real-time Analytics Table
```

### Phase 5: ì‹¤ì‹œê°„ ë¶„ì„
```
ClickHouse Query
    â†“
ì‹¤ì‹œê°„ ëŒ€ì‹œë³´ë“œ ì—…ë°ì´íŠ¸
    â†“
ë¹„ì¦ˆë‹ˆìŠ¤ ì¸ì‚¬ì´íŠ¸ ì¶”ì¶œ
```

## ğŸ—ï¸ ì»´í¬ë„ŒíŠ¸ êµ¬ì„±

### 1. MySQL (Source Database)
- **ì—­í• **: ì£¼ë¬¸ ë°ì´í„° ì €ì¥ ë° Binlog ìƒì„±
- **ë²„ì „**: MySQL 8.0+
- **ì„¤ì •**:
  - binlog í™œì„±í™” (`binlog_format=ROW`)
  - CDC ì „ìš© ì‚¬ìš©ì ê¶Œí•œ ì„¤ì •
- **í…Œì´ë¸”**: `users`, `products`, `orders`, `order_items`
- **ERD**:
  ```
  users (1) â”€â”€â†’ orders (N) â†â”€â”€ order_items (N) â†â”€â”€ products (1)
  ```

### 2. Apache Flink CDC Job
- **ì—­í• **: MySQL Binlog ì‹¤ì‹œê°„ ìº¡ì²˜
- **Connector**: flink-connector-mysql-cdc
- **ê¸°ëŠ¥**:
  - Full Snapshot + Incremental Sync
  - Schema Evolution ì§€ì›
  - Exactly-once ì²˜ë¦¬ ë³´ì¥

### 3. Confluent Kafka (KRaft Mode)
- **ì—­í• **: CDC ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ë²„í¼ë§
- **ì´ë¯¸ì§€**: confluentinc/cp-kafka
- **íŠ¹ì§•**:
  - Zookeeper ë¶ˆí•„ìš” (KRaft ë©”íƒ€ë°ì´í„° ê´€ë¦¬)
  - ê²½ëŸ‰í™”ëœ êµ¬ì„±
  - ë¹ ë¥¸ ì‹œì‘ ì‹œê°„
- **Topic**: `orders-cdc-topic`, `order-items-cdc-topic`

### 4. Apache Flink Sync Connector Job
- **ì—­í• **: Kafka â†’ ClickHouse ì‹¤ì‹œê°„ ë™ê¸°í™”
- **Connector**: flink-connector-kafka + flink-connector-clickhouse
- **ê¸°ëŠ¥**:
  - Batch Insert ìµœì í™”
  - ë°ì´í„° ë³€í™˜ (í•„ìš” ì‹œ)
  - ì˜¤ë¥˜ ì²˜ë¦¬ ë° ì¬ì‹œë„

### 5. ClickHouse (Analytics Database)
- **ì—­í• **: ì‹¤ì‹œê°„ OLAP ë¶„ì„
- **Engine**: MergeTree Family
- **ê¸°ëŠ¥**:
  - ì»¬ëŸ¼ ê¸°ë°˜ ìŠ¤í† ë¦¬ì§€
  - ì‹¤ì‹œê°„ ì§‘ê³„ ì¿¼ë¦¬
  - Materialized View ì§€ì›

### 6. NestJS Platform Service
- **ì—­í• **: í”Œë«í¼ ë°ì´í„° ìƒì„± API
- **ì—”ë“œí¬ì¸íŠ¸**:
  - `POST /api/orders` - ì£¼ë¬¸ ìƒì„±
  - `GET /api/orders` - ì£¼ë¬¸ ì¡°íšŒ
  - `GET /api/orders/:id` - ì£¼ë¬¸ ìƒì„¸
- **DB**: TypeORM + MySQL

### 7. HTML Frontend
- **ì—­í• **: ê°„ë‹¨í•œ ì£¼ë¬¸ ìƒì„± í¼
- **ê¸°ëŠ¥**:
  - ì£¼ë¬¸ ì…ë ¥ ë° ì œì¶œ
  - ì£¼ë¬¸ ëª©ë¡ ì¡°íšŒ
  - ì‹¤ì‹œê°„ í†µê³„ ì¡°íšŒ (ClickHouse)

## ğŸ³ Docker Compose êµ¬ì„±

```yaml
services:
  - mysql (Source DB)
  - kafka (Confluent Kafka KRaft)
  - flink-jobmanager (Flink Master)
  - flink-taskmanager (Flink Worker)
  - clickhouse (Analytics DB)
  - platform-api (Platform Service)
  - nginx (Frontend Static)
```

## ğŸ“ˆ í™•ì¥ì„± ê³ ë ¤ì‚¬í•­

### íŠ¸ë˜í”½ ì¦ê°€ ì‹œ
- **Kafka Partitions**: 3 â†’ 6+ (ë³‘ë ¬ ì²˜ë¦¬)
- **Flink TaskManager**: 1 â†’ N (ìˆ˜í‰ í™•ì¥)
- **ClickHouse Sharding**: ë‹¨ì¼ ë…¸ë“œ â†’ ë¶„ì‚° í´ëŸ¬ìŠ¤í„°

### ë°ì´í„° ë³¼ë¥¨ ì¦ê°€ ì‹œ
- **Kafka Retention**: 7ì¼ â†’ 30ì¼ (ë””ìŠ¤í¬ ì¦ì„¤)
- **ClickHouse Partitioning**: ì›”ë³„ íŒŒí‹°ì…˜
- **MySQL Read Replica**: CDC ì „ìš© Replica ë¶„ë¦¬

## ğŸ”’ ë°ì´í„° ì¼ê´€ì„± ë³´ì¥

### Exactly-Once Semantics
```
MySQL Transaction
    â†“
Flink CDC Checkpoint (State Backend)
    â†“
Kafka Transactional Producer
    â†“
Flink Sync Checkpoint
    â†“
ClickHouse Idempotent Insert
```

### ì¥ì•  ë³µêµ¬
- **Flink Checkpoint**: 1ë¶„ë§ˆë‹¤ ìƒíƒœ ì €ì¥
- **Kafka Offset Commit**: Consumer Group ê¸°ë°˜ ê´€ë¦¬
- **ClickHouse Deduplication**: ReplacingMergeTree ì—”ì§„

## ğŸ“Š ëª¨ë‹ˆí„°ë§ í¬ì¸íŠ¸

### CDC ì§€ì—° ì‹œê°„
```sql
-- Flink CDC ë©”íŠ¸ë¦­
SELECT
    current_timestamp - MAX(event_time) AS cdc_lag
FROM kafka_topic_metadata;
```

### ë°ì´í„° ì •í•©ì„± ì²´í¬
```sql
-- MySQL vs ClickHouse ì¹´ìš´íŠ¸ ë¹„êµ
-- MySQL
SELECT COUNT(*) FROM orders;

-- ClickHouse
SELECT COUNT(*) FROM orders_realtime;
```

### Kafka Consumer Lag
```bash
# Kafka Consumer Group ì§€ì—° í™•ì¸
kafka-consumer-groups --bootstrap-server kafka:9092 \
  --group flink-sync-connector \
  --describe
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### 1. ê¸°ë³¸ ë°ì´í„° íë¦„ í…ŒìŠ¤íŠ¸
```bash
# 1. ì£¼ë¬¸ ìƒì„±
curl -X POST http://localhost:3000/api/orders \
  -H "Content-Type: application/json" \
  -d '{"user_id": 1, "product_name": "Test Product", "quantity": 1, "total_price": 100}'

# 2. ClickHouse í™•ì¸ (ì•½ 1-2ì´ˆ í›„)
docker exec clickhouse-server clickhouse-client \
  --query "SELECT * FROM orders_realtime ORDER BY created_at DESC LIMIT 10"
```

### 2. ëŒ€ëŸ‰ ë°ì´í„° í…ŒìŠ¤íŠ¸
```bash
# 100ê±´ì˜ ì£¼ë¬¸ ìƒì„±
for i in {1..100}; do
  curl -X POST http://localhost:3000/api/orders \
    -H "Content-Type: application/json" \
    -d "{\"user_id\": $i, \"product_name\": \"Product $i\", \"quantity\": 1, \"total_price\": 100}"
done
```

### 3. ì¥ì•  ë³µêµ¬ í…ŒìŠ¤íŠ¸
```bash
# Flink ì¬ì‹œì‘
docker restart flink-jobmanager

# ë°ì´í„° ì¼ê´€ì„± í™•ì¸
# MySQLê³¼ ClickHouse ì¹´ìš´íŠ¸ê°€ ì¼ì¹˜í•´ì•¼ í•¨
```

## ğŸ“ ì„±ëŠ¥ ëª©í‘œ (MVP)

| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì¸¡ì • ë°©ë²• |
|--------|------|-----------|
| CDC ì§€ì—° ì‹œê°„ | < 2ì´ˆ | Event Time - Processing Time |
| End-to-End ì§€ì—° | < 5ì´ˆ | MySQL INSERT â†’ ClickHouse SELECT |
| ì²˜ë¦¬ëŸ‰ | 100-1,000 TPS | Kafka Throughput ë©”íŠ¸ë¦­ |
| ë°ì´í„° ì •í•©ì„± | 100% | MySQL vs ClickHouse Count |

## ğŸš€ ë°°í¬ ìˆœì„œ

1. **ì¸í”„ë¼ ì‹œì‘**
```bash
docker-compose up -d mysql kafka clickhouse
```

2. **Flink Job ë°°í¬**
```bash
# CDC Job ì œì¶œ
docker exec flink-jobmanager flink run \
  /opt/flink/jobs/mysql-cdc-job.jar

# Sync Connector Job ì œì¶œ
docker exec flink-jobmanager flink run \
  /opt/flink/jobs/kafka-clickhouse-sync-job.jar
```

3. **ì• í”Œë¦¬ì¼€ì´ì…˜ ì‹œì‘**
```bash
docker-compose up -d platform-api nginx
```

4. **ê²€ì¦**
```bash
# í—¬ìŠ¤ì²´í¬
curl http://localhost:3000/health
curl http://localhost:8123/ping
```

## ğŸ” ë‹¤ìŒ ë‹¨ê³„
- [Flink CDC MySQL ì„¤ì •](./02-flink-cdc-mysql.md)
- [Confluent Kafka êµ¬ì„±](./03-confluent-kafka.md)
- [Flink Sync Connector ì„¤ì •](./04-flink-sync-connector.md)
- [ClickHouse ìŠ¤í‚¤ë§ˆ ì„¤ê³„](./05-clickhouse-schema.md)
