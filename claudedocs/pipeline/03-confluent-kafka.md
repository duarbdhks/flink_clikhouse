# Confluent Kafka êµ¬ì„± (KRaft ëª¨ë“œ)

## ğŸ“‹ ê°œìš”
Zookeeper ì—†ì´ KRaft ëª¨ë“œë¡œ Confluent Kafkaë¥¼ êµ¬ì„±í•˜ì—¬ CDC ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ì²˜ë¦¬

## ğŸ¯ KRaft ëª¨ë“œë€?
- **KRaft (Kafka Raft)**: Kafka ìì²´ì ìœ¼ë¡œ ë©”íƒ€ë°ì´í„°ë¥¼ ê´€ë¦¬í•˜ëŠ” ìƒˆë¡œìš´ ì•„í‚¤í…ì²˜
- **Zookeeper ë¶ˆí•„ìš”**: ê²½ëŸ‰í™” ë° ê´€ë¦¬ ë³µì¡ë„ ê°ì†Œ
- **Kafka 2.8+ ì§€ì›**, **Kafka 3.3+ í”„ë¡œë•ì…˜ ì‚¬ìš© ê¶Œì¥**
- **Confluent 7.0+**: KRaft ì•ˆì •í™” ë²„ì „

## ğŸ—ï¸ ì•„í‚¤í…ì²˜

```mermaid
graph TB
    FlinkCDC[Flink CDC Job] -->|Change Events| Kafka[Kafka Broker<br/>KRaft Mode]
    Kafka -->|orders-cdc-topic| FlinkSync[Flink Sync Connector]
    Kafka -->|order-items-cdc-topic| FlinkSync

    Kafka -->|Metadata Storage| KRaftLog[KRaft Log<br/>Internal Topic]

    style Kafka fill:#231F20,color:#fff
    style KRaftLog fill:#666,color:#fff
```

## ğŸ³ Docker Compose ì„¤ì •

### ê¸°ë³¸ êµ¬ì„± (confluentinc/cp-kafka)
```yaml
services:
  kafka:
    image: confluentinc/cp-kafka:7.6.0
    container_name: kafka
    hostname: kafka
    ports:
      - "9092:9092"    # ì™¸ë¶€ ì ‘ì†ìš©
      - "9093:9093"    # ì»¨íŠ¸ë¡¤ëŸ¬ í†µì‹ ìš©
    environment:
      # KRaft ëª¨ë“œ ì„¤ì •
      KAFKA_NODE_ID: 1
      KAFKA_PROCESS_ROLES: broker,controller
      KAFKA_CONTROLLER_QUORUM_VOTERS: 1@kafka:9093
      KAFKA_CONTROLLER_LISTENER_NAMES: CONTROLLER

      # ë¦¬ìŠ¤ë„ˆ ì„¤ì •
      KAFKA_LISTENERS: PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:9092
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,CONTROLLER:PLAINTEXT
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT

      # í´ëŸ¬ìŠ¤í„° ID (UUID í˜•ì‹)
      CLUSTER_ID: MkU3OEVBNTcwNTJENDM2Qk

      # ë¡œê·¸ ë””ë ‰í† ë¦¬
      KAFKA_LOG_DIRS: /var/lib/kafka/data

      # ì„±ëŠ¥ íŠœë‹
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1

      # ë¡œê·¸ ë³´ê´€ ì •ì±…
      KAFKA_LOG_RETENTION_HOURS: 168  # 7ì¼
      KAFKA_LOG_SEGMENT_BYTES: 1073741824  # 1GB

      # JVM í™ ë©”ëª¨ë¦¬
      KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"

    volumes:
      - kafka-data:/var/lib/kafka/data
    networks:
      - cdc-network
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:9092"]
      interval: 10s
      timeout: 5s
      retries: 5

volumes:
  kafka-data:
    driver: local

networks:
  cdc-network:
    driver: bridge
```

### í´ëŸ¬ìŠ¤í„° ID ìƒì„± ë°©ë²•
```bash
# í´ëŸ¬ìŠ¤í„° ID ìƒì„± (UUID)
docker run --rm confluentinc/cp-kafka:7.6.0 kafka-storage random-uuid

# ì¶œë ¥ ì˜ˆì‹œ:
# MkU3OEVBNTcwNTJENDM2Qk
```

## ğŸ“Œ Topic ì„¤ê³„

### 1. orders-cdc-topic
```yaml
Topic Name: orders-cdc-topic
Purpose: orders í…Œì´ë¸” CDC ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼
Partitions: 1  # CDC ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ 1ê°œë¡œ ì„¤ì •
Replication Factor: 1 (ë‹¨ì¼ ë¸Œë¡œì»¤)
Retention: 7 days
Cleanup Policy: delete
```

### 2. order-items-cdc-topic
```yaml
Topic Name: order-items-cdc-topic
Purpose: order_items í…Œì´ë¸” CDC ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼
Partitions: 1  # CDC ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ 1ê°œë¡œ ì„¤ì •
Replication Factor: 1
Retention: 7 days
Cleanup Policy: delete
```

### Topic ìƒì„± ìŠ¤í¬ë¦½íŠ¸
```bash
#!/bin/bash

# Topic ìƒì„± í•¨ìˆ˜
create_topic() {
  local topic_name=$1
  local partitions=$2
  local retention_ms=$3

  docker exec -it kafka kafka-topics --create \
    --bootstrap-server localhost:9092 \
    --topic ${topic_name} \
    --partitions ${partitions} \
    --replication-factor 1 \
    --config retention.ms=${retention_ms} \
    --config cleanup.policy=delete

  echo "âœ… Topic '${topic_name}' created with ${partitions} partitions"
}

# CDC Topics ìƒì„± (CDC ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ íŒŒí‹°ì…˜ 1ê°œ)
create_topic "orders-cdc-topic" 1 604800000       # 7ì¼ (7 * 24 * 60 * 60 * 1000)
create_topic "order-items-cdc-topic" 1 604800000  # 7ì¼

# Topic ëª©ë¡ í™•ì¸
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092
```

## ğŸ”§ Kafka ê´€ë¦¬ ëª…ë ¹ì–´

### Topic ê´€ë¦¬
```bash
# 1. Topic ëª©ë¡ í™•ì¸
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092

# 2. Topic ìƒì„¸ ì •ë³´
docker exec -it kafka kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic

# 3. Topic ì‚­ì œ
docker exec -it kafka kafka-topics --delete \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic

# 4. Topic ì„¤ì • ë³€ê²½ (retention ê¸°ê°„)
docker exec -it kafka kafka-configs --alter \
  --bootstrap-server localhost:9092 \
  --entity-type topics \
  --entity-name orders-cdc-topic \
  --add-config retention.ms=1209600000  # 14ì¼
```

### Producer í…ŒìŠ¤íŠ¸
```bash
# ì½˜ì†” í”„ë¡œë“€ì„œë¡œ í…ŒìŠ¤íŠ¸ ë©”ì‹œì§€ ì „ì†¡
docker exec -it kafka kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic

# ì…ë ¥ (Ctrl+Dë¡œ ì¢…ë£Œ):
# {"order_id": 1, "user_id": 100, "product_name": "Test", "quantity": 1}
```

### Consumer í…ŒìŠ¤íŠ¸
```bash
# 1. ì²˜ìŒë¶€í„° ëª¨ë“  ë©”ì‹œì§€ ì½ê¸°
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic \
  --from-beginning

# 2. ìµœì‹  ë©”ì‹œì§€ë§Œ ì½ê¸°
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic

# 3. Consumer Groupìœ¼ë¡œ ì½ê¸°
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic \
  --group flink-sync-consumer \
  --from-beginning

# 4. íŠ¹ì • ê°œìˆ˜ë§Œ ì½ê¸°
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic \
  --from-beginning \
  --max-messages 10
```

### Consumer Group ê´€ë¦¬
```bash
# 1. Consumer Group ëª©ë¡
docker exec -it kafka kafka-consumer-groups --list \
  --bootstrap-server localhost:9092

# 2. Consumer Group ìƒì„¸ ì •ë³´ (Lag í™•ì¸)
docker exec -it kafka kafka-consumer-groups --describe \
  --bootstrap-server localhost:9092 \
  --group flink-sync-consumer

# 3. Consumer Group Offset ë¦¬ì…‹
docker exec -it kafka kafka-consumer-groups --reset-offsets \
  --bootstrap-server localhost:9092 \
  --group flink-sync-consumer \
  --topic orders-cdc-topic \
  --to-earliest \
  --execute
```

## ğŸ“Š ë©”ì‹œì§€ í˜•ì‹ ì˜ˆì‹œ

### CDC Insert Event
```json
{
  "before": null,
  "after": {
    "order_id": 1001,
    "user_id": 500,
    "product_name": "Laptop",
    "quantity": 2,
    "total_price": 2000.00,
    "status": "pending",
    "created_at": "2025-01-11T10:30:00Z",
    "updated_at": "2025-01-11T10:30:00Z"
  },
  "source": {
    "version": "3.0.1",
    "connector": "mysql",
    "name": "mysql-server",
    "ts_ms": 1736592600000,
    "db": "order_db",
    "table": "orders",
    "server_id": 1,
    "file": "mysql-bin.000003",
    "pos": 1234
  },
  "op": "c",
  "ts_ms": 1736592600123
}
```

### CDC Update Event
```json
{
  "before": {
    "order_id": 1001,
    "user_id": 500,
    "product_name": "Laptop",
    "quantity": 2,
    "total_price": 2000.00,
    "status": "pending",
    "created_at": "2025-01-11T10:30:00Z",
    "updated_at": "2025-01-11T10:30:00Z"
  },
  "after": {
    "order_id": 1001,
    "user_id": 500,
    "product_name": "Laptop",
    "quantity": 2,
    "total_price": 2000.00,
    "status": "completed",
    "created_at": "2025-01-11T10:30:00Z",
    "updated_at": "2025-01-11T11:45:00Z"
  },
  "source": {
    "version": "3.0.1",
    "connector": "mysql",
    "name": "mysql-server",
    "ts_ms": 1736596500000,
    "db": "order_db",
    "table": "orders",
    "server_id": 1,
    "file": "mysql-bin.000003",
    "pos": 5678
  },
  "op": "u",
  "ts_ms": 1736596500456
}
```

### CDC Delete Event
```json
{
  "before": {
    "order_id": 1001,
    "user_id": 500,
    "product_name": "Laptop",
    "quantity": 2,
    "total_price": 2000.00,
    "status": "completed",
    "created_at": "2025-01-11T10:30:00Z",
    "updated_at": "2025-01-11T11:45:00Z"
  },
  "after": null,
  "source": {
    "version": "3.0.1",
    "connector": "mysql",
    "name": "mysql-server",
    "ts_ms": 1736600100000,
    "db": "order_db",
    "table": "orders",
    "server_id": 1,
    "file": "mysql-bin.000003",
    "pos": 9012
  },
  "op": "d",
  "ts_ms": 1736600100789
}
```

## ğŸ” ëª¨ë‹ˆí„°ë§

### Kafka ë©”íŠ¸ë¦­ í™•ì¸
```bash
# JMX ë©”íŠ¸ë¦­ ì¡°íšŒ
docker exec -it kafka kafka-run-class kafka.tools.JmxTool \
  --object-name kafka.server:type=BrokerTopicMetrics,name=MessagesInPerSec

# Broker ë©”íƒ€ë°ì´í„°
docker exec -it kafka kafka-metadata-shell \
  --snapshot /var/lib/kafka/data/__cluster_metadata-0/00000000000000000000.log \
  --print-controllers
```

### Kafka UI ë„êµ¬ ì¶”ê°€ (ì„ íƒì )
```yaml
services:
  kafka-ui:
    image: provectuslabs/kafka-ui:latest
    container_name: kafka-ui
    ports:
      - "8080:8080"
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: kafka:9092
    depends_on:
      - kafka
    networks:
      - cdc-network
```

**ì ‘ì†**: http://localhost:8080

## âš™ï¸ ì„±ëŠ¥ íŠœë‹

### MVP í™˜ê²½ (ì†Œê·œëª¨ íŠ¸ë˜í”½)
```yaml
environment:
  # CDC Topic Partition (ìˆœì„œ ë³´ì¥ì„ ìœ„í•´ 1ë¡œ ì„¤ì •)
  KAFKA_NUM_PARTITIONS: 1

  # Replication Factor
  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
  KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1

  # ë©”ëª¨ë¦¬ ìµœì í™”
  KAFKA_HEAP_OPTS: "-Xmx512M -Xms512M"

  # ë¡œê·¸ ì„¸ê·¸ë¨¼íŠ¸ í¬ê¸°
  KAFKA_LOG_SEGMENT_BYTES: 536870912  # 512MB

  # Flush ì •ì±… (ë¹„ë™ê¸°)
  KAFKA_LOG_FLUSH_INTERVAL_MESSAGES: 10000
  KAFKA_LOG_FLUSH_INTERVAL_MS: 1000
```

### í”„ë¡œë•ì…˜ í™˜ê²½ (ëŒ€ê·œëª¨ íŠ¸ë˜í”½)
```yaml
environment:
  # CDC Topic Partition (Key ê¸°ë°˜ íŒŒí‹°ì…”ë‹ í•„ìˆ˜!)
  # ì£¼ì˜: Flink CDCì—ì„œ order_idë¥¼ Kafka Keyë¡œ ì„¤ì •í•´ì•¼ ìˆœì„œ ë³´ì¥
  KAFKA_NUM_PARTITIONS: 6

  # Replication Factor
  KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 3
  KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 3

  # ë©”ëª¨ë¦¬ í™•ëŒ€
  KAFKA_HEAP_OPTS: "-Xmx4G -Xms4G"

  # ì••ì¶• í™œì„±í™”
  KAFKA_COMPRESSION_TYPE: snappy

  # Retention ì—°ì¥
  KAFKA_LOG_RETENTION_HOURS: 720  # 30ì¼
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### 1. Kafka ì •ìƒ ë™ì‘ í™•ì¸
```bash
# 1. Kafka ì»¨í…Œì´ë„ˆ ìƒíƒœ
docker ps | grep kafka

# 2. Kafka ë¡œê·¸ í™•ì¸
docker logs kafka -f

# 3. Broker ìƒíƒœ í™•ì¸
docker exec -it kafka kafka-broker-api-versions --bootstrap-server localhost:9092
```

### 2. Topic ìƒì„± ë° ë©”ì‹œì§€ ì „ì†¡
```bash
# Topic ìƒì„±
docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --partitions 1 \
  --replication-factor 1

# Producer ì‹¤í–‰
docker exec -it kafka kafka-console-producer \
  --bootstrap-server localhost:9092 \
  --topic test-topic

# ë©”ì‹œì§€ ì…ë ¥:
# Hello Kafka
# Test Message

# Consumer ì‹¤í–‰ (ë‹¤ë¥¸ í„°ë¯¸ë„)
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic test-topic \
  --from-beginning
```

### 3. CDC íŒŒì´í”„ë¼ì¸ í†µí•© í…ŒìŠ¤íŠ¸
```bash
# 1. MySQLì— ë°ì´í„° ì‚½ì…
docker exec -it mysql mysql -u root -p
USE order_db;
INSERT INTO orders (user_id, product_name, quantity, total_price)
VALUES (100, 'Test Product', 1, 50.00);

# 2. Kafka Topicì—ì„œ CDC ì´ë²¤íŠ¸ í™•ì¸
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic \
  --from-beginning

# 3. Consumer Lag í™•ì¸
docker exec -it kafka kafka-consumer-groups --describe \
  --bootstrap-server localhost:9092 \
  --group flink-sync-consumer
```

## ğŸš¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: Kafka ì‹œì‘ ì‹¤íŒ¨
```bash
# ë¡œê·¸ í™•ì¸
docker logs kafka

# ì¼ë°˜ì ì¸ ì›ì¸:
# - CLUSTER_ID ë¯¸ì„¤ì •
# - í¬íŠ¸ ì¶©ëŒ (9092, 9093)
# - ë³¼ë¥¨ ê¶Œí•œ ë¬¸ì œ

# í•´ê²°: ë³¼ë¥¨ ì´ˆê¸°í™”
docker-compose down -v
docker-compose up -d kafka
```

### ë¬¸ì œ 2: Topic ìƒì„± ì‹¤íŒ¨
```bash
# Broker ì—°ê²° í™•ì¸
docker exec -it kafka kafka-broker-api-versions --bootstrap-server localhost:9092

# ë„¤íŠ¸ì›Œí¬ í™•ì¸
docker network inspect cdc-network
```

### ë¬¸ì œ 3: Consumer Lag ì¦ê°€
```bash
# Lag í™•ì¸
docker exec -it kafka kafka-consumer-groups --describe \
  --bootstrap-server localhost:9092 \
  --group flink-sync-consumer

# ì›ì¸:
# - Consumer ì²˜ë¦¬ ì†ë„ < Producer ì²˜ë¦¬ ì†ë„
# - Flink Sync Connector Job ì¤‘ë‹¨

# í•´ê²°:
# - Partition ìˆ˜ ì¦ê°€
# - Consumer ë³‘ë ¬ë„ ì¦ê°€ (Flink TaskManager)
```

### ë¬¸ì œ 4: ë©”ì‹œì§€ ì†ì‹¤
```bash
# Producer ACK ì„¤ì • í™•ì¸
KAFKA_ACKS: all  # ëª¨ë“  Replica í™•ì¸

# Replication Factor í™•ì¸
docker exec -it kafka kafka-topics --describe \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic

# min.insync.replicas ì„¤ì • (í”„ë¡œë•ì…˜)
KAFKA_MIN_INSYNC_REPLICAS: 2
```

## ğŸ”’ ë³´ì•ˆ ì„¤ì • (ì„ íƒì )

### SASL/SCRAM ì¸ì¦
```yaml
environment:
  # SASL í™œì„±í™”
  KAFKA_SASL_ENABLED_MECHANISMS: SCRAM-SHA-256
  KAFKA_SASL_MECHANISM_INTER_BROKER_PROTOCOL: SCRAM-SHA-256

  # Listener ìˆ˜ì •
  KAFKA_LISTENERS: SASL_PLAINTEXT://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
  KAFKA_ADVERTISED_LISTENERS: SASL_PLAINTEXT://kafka:9092
  KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: SASL_PLAINTEXT:SASL_PLAINTEXT,CONTROLLER:PLAINTEXT
```

### SSL ì•”í˜¸í™”
```yaml
environment:
  KAFKA_LISTENERS: SSL://0.0.0.0:9092,CONTROLLER://0.0.0.0:9093
  KAFKA_ADVERTISED_LISTENERS: SSL://kafka:9092
  KAFKA_SSL_KEYSTORE_LOCATION: /etc/kafka/secrets/kafka.keystore.jks
  KAFKA_SSL_KEYSTORE_PASSWORD: changeit
  KAFKA_SSL_KEY_PASSWORD: changeit
  KAFKA_SSL_TRUSTSTORE_LOCATION: /etc/kafka/secrets/kafka.truststore.jks
  KAFKA_SSL_TRUSTSTORE_PASSWORD: changeit
```

## ğŸ¯ CDC Partition ì „ëµ

### MVP ê¶Œì¥: íŒŒí‹°ì…˜ 1ê°œ (ìˆœì„œ ë³´ì¥ ìš°ì„ )

**ì´ìœ **:
1. **ìˆœì„œ ë³´ì¥**: CDC ì´ë²¤íŠ¸ëŠ” ìˆœì„œê°€ ì¤‘ìš” (INSERT â†’ UPDATE â†’ DELETE)
2. **ë°ì´í„° ì •í•©ì„±**: ìˆœì„œê°€ ë’¤ë°”ë€Œë©´ ë°ì´í„° ì†ì‹¤/ì˜¤ë¥˜ ë°œìƒ ê°€ëŠ¥
3. **ì¶©ë¶„í•œ ì„±ëŠ¥**: MVP ëª©í‘œ 100-1,000 TPSëŠ” íŒŒí‹°ì…˜ 1ê°œë¡œë„ ì²˜ë¦¬ ê°€ëŠ¥
4. **ë‹¨ìˆœì„±**: Key ì„¤ì • ë¶ˆí•„ìš”, Flink CDC ì½”ë“œ ìˆ˜ì • ìµœì†Œí™”

**ìˆœì„œ ë³´ì¥ ì˜ˆì‹œ**:
```
âœ… ì˜¬ë°”ë¥¸ ìˆœì„œ (íŒŒí‹°ì…˜ 1ê°œ):
1. INSERT order_id=100, status='PENDING'
2. UPDATE order_id=100, status='CONFIRMED'
3. DELETE order_id=100

âŒ ì˜ëª»ëœ ìˆœì„œ (íŒŒí‹°ì…˜ 3ê°œ, Key ì—†ìŒ):
1. DELETE order_id=100  â† ë¨¼ì € ì‚­ì œ
2. INSERT order_id=100  â† ë‚˜ì¤‘ì— ì‚½ì… (ìˆœì„œ ì—­ì „!)
3. UPDATE order_id=100  â† ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ë°ì´í„° ì—…ë°ì´íŠ¸
```

### í”„ë¡œë•ì…˜ ê³ ë ¤ì‚¬í•­: íŒŒí‹°ì…˜ ì¦ê°€ (Key ê¸°ë°˜ íŒŒí‹°ì…”ë‹)

**ì¡°ê±´**:
- ì²˜ë¦¬ëŸ‰ > 10,000 TPS
- Flink CDCì—ì„œ **order_idë¥¼ Kafka Message Keyë¡œ ì„¤ì •**
- ê°™ì€ order_idëŠ” ê°™ì€ íŒŒí‹°ì…˜ìœ¼ë¡œ ì „ì†¡ ë³´ì¥

**Flink CDC ì½”ë“œ ìˆ˜ì • ì˜ˆì‹œ** (í”„ë¡œë•ì…˜ ì‹œ):
```java
// order_idë¥¼ Keyë¡œ ì¶”ì¶œí•˜ëŠ” Serializer êµ¬í˜„ í•„ìš”
KafkaSink<String> ordersSink = KafkaSink.<String>builder()
    .setBootstrapServers(CDCConfig.KAFKA_BOOTSTRAP_SERVERS)
    .setRecordSerializer(
        KafkaRecordSerializationSchema.builder()
            .setTopic(CDCConfig.KAFKA_TOPIC_ORDERS)
            .setKeySerializationSchema(new OrderIdKeySerializer())  // â† Key ì¶”ì¶œ
            .setValueSerializationSchema(new SimpleStringSchema())
            .build()
    )
    .build();
```

**ì¥ì **:
- âœ… ë†’ì€ ì²˜ë¦¬ëŸ‰ (ë³‘ë ¬ ì²˜ë¦¬)
- âœ… í™•ì¥ì„± (Consumer ì¶”ê°€ ê°€ëŠ¥)
- âœ… ê°™ì€ order_idëŠ” ìˆœì„œ ë³´ì¥

**ë‹¨ì **:
- âŒ êµ¬í˜„ ë³µì¡ë„ ì¦ê°€ (Key Serializer êµ¬í˜„)
- âŒ íŒŒí‹°ì…˜ ê°„ ìˆœì„œ ë³´ì¥ ì•ˆë¨ (ë‹¤ë¥¸ order_id)

## ğŸ“š ì°¸ê³  ìë£Œ
- [Confluent Kafka Docker ê°€ì´ë“œ](https://docs.confluent.io/platform/current/installation/docker/config-reference.html)
- [KRaft ëª¨ë“œ ê³µì‹ ë¬¸ì„œ](https://kafka.apache.org/documentation/#kraft)
- [Kafka Topic ì„¤ì • Best Practices](https://kafka.apache.org/documentation/#topicconfigs)

## ğŸ” ë‹¤ìŒ ë‹¨ê³„
- [Flink Sync Connector ì„¤ì •](./04-flink-sync-connector.md) - Kafka â†’ ClickHouse ë™ê¸°í™”
- [ClickHouse ìŠ¤í‚¤ë§ˆ ì„¤ê³„](./05-clickhouse-schema.md) - ì‹¤ì‹œê°„ ë¶„ì„ í…Œì´ë¸”
