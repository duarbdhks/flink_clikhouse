# íŒŒì´í”„ë¼ì¸ E2E í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## ğŸ“‹ ê°œìš”
ì „ì²´ ë°ì´í„° íŒŒì´í”„ë¼ì¸ì˜ ì •ìƒ ë™ì‘ì„ ê²€ì¦í•˜ëŠ” End-to-End í…ŒìŠ¤íŠ¸ ê°€ì´ë“œ

## ğŸ¯ í…ŒìŠ¤íŠ¸ ëª©í‘œ
- **ë°ì´í„° íë¦„ ê²€ì¦**: MySQL â†’ Flink CDC â†’ Kafka â†’ Flink Sync â†’ ClickHouse
- **ë°ì´í„° ì •í•©ì„± ê²€ì¦**: ì†ŒìŠ¤ ë°ì´í„°ì™€ íƒ€ê²Ÿ ë°ì´í„° ì¼ì¹˜ í™•ì¸
- **ì‹¤ì‹œê°„ ë™ê¸°í™” ê²€ì¦**: ì§€ì—° ì‹œê°„ ë° ì²˜ë¦¬ëŸ‰ ì¸¡ì •
- **ì¥ì•  ë³µêµ¬ ê²€ì¦**: ì»´í¬ë„ŒíŠ¸ ì¥ì•  ì‹œ ë³µêµ¬ ëŠ¥ë ¥ í™•ì¸

## ğŸ”§ ì‚¬ì „ ì¤€ë¹„

### 1. ì „ì²´ ì¸í”„ë¼ ì‹œì‘
```bash
# ëª¨ë“  ì„œë¹„ìŠ¤ ì‹œì‘
docker-compose up -d

# ì„œë¹„ìŠ¤ ìƒíƒœ í™•ì¸
docker-compose ps

# ëª¨ë“  ì»¨í…Œì´ë„ˆê°€ healthy ìƒíƒœì¸ì§€ í™•ì¸
# NAME                  STATUS
# mysql                 Up (healthy)
# kafka                 Up (healthy)
# clickhouse-server     Up (healthy)
# flink-jobmanager      Up (healthy)
# flink-taskmanager     Up
```

### 2. Kafka Topic ìƒì„±
```bash
# Topic ìƒì„±
docker exec -it kafka kafka-topics --create \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic \
  --partitions 3 \
  --replication-factor 1

# Topic í™•ì¸
docker exec -it kafka kafka-topics --list --bootstrap-server localhost:9092
```

### 3. ClickHouse í…Œì´ë¸” í™•ì¸
```bash
docker exec -it clickhouse-server clickhouse-client \
  --query "SHOW TABLES FROM order_analytics"

# ì˜ˆìƒ ì¶œë ¥:
# orders_realtime
# orders_daily_summary
# orders_hourly_stats
```

## ğŸ§ª í…ŒìŠ¤íŠ¸ ì‹œë‚˜ë¦¬ì˜¤

### Test 1: ê¸°ë³¸ ë°ì´í„° íë¦„ ê²€ì¦

#### ëª©ì 
MySQL INSERT â†’ ClickHouse INSERT ì „ì²´ íë¦„ í™•ì¸

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# 1. MySQL ì´ˆê¸° ì¹´ìš´íŠ¸ í™•ì¸
docker exec -it mysql mysql -u root -proot_password order_db \
  -e "SELECT COUNT(*) AS mysql_count FROM orders"

# 2. ClickHouse ì´ˆê¸° ì¹´ìš´íŠ¸ í™•ì¸
docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT COUNT(*) AS ch_count FROM order_analytics.orders_realtime"

# 3. MySQLì— ìƒˆ ì£¼ë¬¸ ì‚½ì…
docker exec -it mysql mysql -u root -proot_password order_db \
  -e "INSERT INTO orders (user_id, product_name, quantity, total_price, status) VALUES (500, 'Test Laptop', 1, 1200.00, 'pending')"

# 4. Kafkaì—ì„œ CDC ì´ë²¤íŠ¸ í™•ì¸ (1-2ì´ˆ ëŒ€ê¸°)
sleep 2
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic \
  --max-messages 1 \
  --timeout-ms 5000

# 5. ClickHouseì—ì„œ ë°ì´í„° í™•ì¸ (3-7ì´ˆ ëŒ€ê¸°)
sleep 5
docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT * FROM order_analytics.orders_realtime WHERE user_id = 500 ORDER BY event_timestamp DESC LIMIT 1"

# 6. ìµœì¢… ì¹´ìš´íŠ¸ ë¹„êµ
docker exec -it mysql mysql -u root -proot_password order_db \
  -e "SELECT COUNT(*) AS mysql_count FROM orders"

docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT COUNT(*) AS ch_count FROM order_analytics.orders_realtime WHERE operation_type != 'DELETE'"
```

#### ì˜ˆìƒ ê²°ê³¼
```
âœ… Kafkaì— CDC ì´ë²¤íŠ¸ ìˆ˜ì‹ ë¨
âœ… ClickHouseì— ë ˆì½”ë“œ ì‚½ì…ë¨
âœ… MySQL ì¹´ìš´íŠ¸ = ClickHouse ì¹´ìš´íŠ¸
```

### Test 2: UPDATE ì´ë²¤íŠ¸ ì²˜ë¦¬

#### ëª©ì 
UPDATE ì‘ì—…ì´ ClickHouseì— ì •ìƒ ë°˜ì˜ë˜ëŠ”ì§€ í™•ì¸

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# 1. íŠ¹ì • ì£¼ë¬¸ ì¡°íšŒ
docker exec -it mysql mysql -u root -proot_password order_db \
  -e "SELECT order_id, status FROM orders WHERE user_id = 500"

# 2. ìƒíƒœ ì—…ë°ì´íŠ¸ (pending â†’ completed)
docker exec -it mysql mysql -u root -proot_password order_db \
  -e "UPDATE orders SET status = 'completed' WHERE user_id = 500"

# 3. ClickHouseì—ì„œ UPDATE ì´ë²¤íŠ¸ í™•ì¸ (5ì´ˆ ëŒ€ê¸°)
sleep 5
docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT order_id, status, operation_type, event_timestamp FROM order_analytics.orders_realtime WHERE user_id = 500 ORDER BY event_timestamp DESC LIMIT 2"
```

#### ì˜ˆìƒ ê²°ê³¼
```
âœ… 2ê°œì˜ ë ˆì½”ë“œ ì¡°íšŒë¨ (INSERT, UPDATE)
âœ… ìµœì‹  ë ˆì½”ë“œì˜ status = 'completed'
âœ… operation_type = 'UPDATE'
```

### Test 3: DELETE ì´ë²¤íŠ¸ ì²˜ë¦¬

#### ëª©ì 
DELETE ì‘ì—…ì´ ë…¼ë¦¬ì  ì‚­ì œë¡œ ì²˜ë¦¬ë˜ëŠ”ì§€ í™•ì¸

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# 1. ì£¼ë¬¸ ì‚­ì œ
docker exec -it mysql mysql -u root -proot_password order_db \
  -e "DELETE FROM orders WHERE user_id = 500"

# 2. ClickHouseì—ì„œ DELETE ì´ë²¤íŠ¸ í™•ì¸ (5ì´ˆ ëŒ€ê¸°)
sleep 5
docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT order_id, status, operation_type FROM order_analytics.orders_realtime WHERE user_id = 500 ORDER BY event_timestamp DESC LIMIT 3"
```

#### ì˜ˆìƒ ê²°ê³¼
```
âœ… 3ê°œì˜ ë ˆì½”ë“œ ì¡°íšŒë¨ (INSERT, UPDATE, DELETE)
âœ… ìµœì‹  ë ˆì½”ë“œì˜ operation_type = 'DELETE'
âœ… before ë°ì´í„°ê°€ ClickHouseì— ì €ì¥ë¨
```

### Test 4: ëŒ€ëŸ‰ ë°ì´í„° ì²˜ë¦¬

#### ëª©ì 
ì²˜ë¦¬ëŸ‰(Throughput) ë° ì§€ì—° ì‹œê°„(Latency) ì¸¡ì •

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# 1. ì‹œì‘ ì‹œê°„ ê¸°ë¡
START_TIME=$(date +%s)

# 2. 100ê±´ì˜ ì£¼ë¬¸ ìƒì„±
for i in {1..100}; do
  docker exec -it mysql mysql -u root -proot_password order_db \
    -e "INSERT INTO orders (user_id, product_name, quantity, total_price) VALUES ($((1000+i)), 'Product $i', 1, $((100+i)).00)"
done

# 3. ì¢…ë£Œ ì‹œê°„ ê¸°ë¡
END_TIME=$(date +%s)
DURATION=$((END_TIME - START_TIME))

echo "âœ… 100ê±´ INSERT ì™„ë£Œ (ì†Œìš” ì‹œê°„: ${DURATION}ì´ˆ)"

# 4. MySQL ìµœì¢… ì¹´ìš´íŠ¸
MYSQL_COUNT=$(docker exec -it mysql mysql -u root -proot_password order_db \
  -se "SELECT COUNT(*) FROM orders WHERE user_id >= 1001 AND user_id <= 1100")

# 5. 30ì´ˆ ëŒ€ê¸° (íŒŒì´í”„ë¼ì¸ ì²˜ë¦¬ ì‹œê°„)
echo "â³ 30ì´ˆ ëŒ€ê¸° ì¤‘..."
sleep 30

# 6. ClickHouse ìµœì¢… ì¹´ìš´íŠ¸
CH_COUNT=$(docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT COUNT(*) FROM order_analytics.orders_realtime WHERE user_id >= 1001 AND user_id <= 1100 AND operation_type != 'DELETE'")

# 7. ê²°ê³¼ ë¹„êµ
echo "MySQL ì¹´ìš´íŠ¸: ${MYSQL_COUNT}"
echo "ClickHouse ì¹´ìš´íŠ¸: ${CH_COUNT}"

if [ "$MYSQL_COUNT" -eq "$CH_COUNT" ]; then
  echo "âœ… ë°ì´í„° ì •í•©ì„± ê²€ì¦ ì„±ê³µ"
else
  echo "âŒ ë°ì´í„° ë¶ˆì¼ì¹˜ ë°œê²¬"
fi
```

#### ì˜ˆìƒ ê²°ê³¼
```
âœ… 100ê±´ INSERT ì™„ë£Œ (ì†Œìš” ì‹œê°„: 15-30ì´ˆ)
âœ… MySQL ì¹´ìš´íŠ¸: 100
âœ… ClickHouse ì¹´ìš´íŠ¸: 100
âœ… ë°ì´í„° ì •í•©ì„± ê²€ì¦ ì„±ê³µ
```

### Test 5: ì§€ì—° ì‹œê°„ ì¸¡ì •

#### ëª©ì 
End-to-End ì§€ì—° ì‹œê°„(Latency) ì¸¡ì •

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
cat > test_latency.sh << 'EOF'
#!/bin/bash

# í…ŒìŠ¤íŠ¸ íšŸìˆ˜
TEST_COUNT=10

echo "ì§€ì—° ì‹œê°„ ì¸¡ì • ì‹œì‘ (${TEST_COUNT}íšŒ)"
echo "=========================================="

TOTAL_LATENCY=0

for i in $(seq 1 $TEST_COUNT); do
  # 1. MySQL INSERT ì‹œì‘ ì‹œê°„
  INSERT_START=$(date +%s%3N)  # ë°€ë¦¬ì´ˆ

  # 2. ì£¼ë¬¸ ì‚½ì…
  ORDER_ID=$(docker exec -it mysql mysql -u root -proot_password order_db \
    -se "INSERT INTO orders (user_id, product_name, quantity, total_price) VALUES ($((2000+i)), 'Latency Test $i', 1, 100.00); SELECT LAST_INSERT_ID();")

  # 3. ClickHouseì—ì„œ ëŒ€ê¸° ë° í™•ì¸
  while true; do
    COUNT=$(docker exec -it clickhouse-server clickhouse-client \
      --query "SELECT COUNT(*) FROM order_analytics.orders_realtime WHERE order_id = ${ORDER_ID}")

    if [ "$COUNT" -ge 1 ]; then
      INSERT_END=$(date +%s%3N)
      LATENCY=$((INSERT_END - INSERT_START))
      TOTAL_LATENCY=$((TOTAL_LATENCY + LATENCY))
      echo "Test $i: ${LATENCY}ms"
      break
    fi

    sleep 0.1
  done
done

AVG_LATENCY=$((TOTAL_LATENCY / TEST_COUNT))
echo "=========================================="
echo "í‰ê·  ì§€ì—° ì‹œê°„: ${AVG_LATENCY}ms"
EOF

chmod +x test_latency.sh
./test_latency.sh
```

#### ì˜ˆìƒ ê²°ê³¼
```
âœ… í‰ê·  ì§€ì—° ì‹œê°„: 2000-5000ms (2-5ì´ˆ)
MVP ëª©í‘œ: < 5ì´ˆ
```

### Test 6: Flink Job ì¬ì‹œì‘ (ì¥ì•  ë³µêµ¬)

#### ëª©ì 
Flink Job ì¬ì‹œì‘ í›„ ë°ì´í„° ì¼ê´€ì„± ìœ ì§€ í™•ì¸

#### í…ŒìŠ¤íŠ¸ ì‹¤í–‰
```bash
# 1. ì´ˆê¸° ì¹´ìš´íŠ¸ ê¸°ë¡
INITIAL_COUNT=$(docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT COUNT(*) FROM order_analytics.orders_realtime")

echo "ì´ˆê¸° ClickHouse ì¹´ìš´íŠ¸: ${INITIAL_COUNT}"

# 2. Flink JobManager ì¬ì‹œì‘
docker restart flink-jobmanager

echo "â³ Flink ì¬ì‹œì‘ ì¤‘... (30ì´ˆ ëŒ€ê¸°)"
sleep 30

# 3. Job ìƒíƒœ í™•ì¸
docker exec -it flink-jobmanager flink list

# 4. MySQLì— ìƒˆ ë°ì´í„° ì‚½ì…
docker exec -it mysql mysql -u root -proot_password order_db \
  -e "INSERT INTO orders (user_id, product_name, quantity, total_price) VALUES (3000, 'Recovery Test', 1, 100.00)"

# 5. ClickHouse í™•ì¸ (10ì´ˆ ëŒ€ê¸°)
sleep 10
FINAL_COUNT=$(docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT COUNT(*) FROM order_analytics.orders_realtime")

echo "ìµœì¢… ClickHouse ì¹´ìš´íŠ¸: ${FINAL_COUNT}"

# 6. ì¦ê°€ëŸ‰ í™•ì¸
DIFF=$((FINAL_COUNT - INITIAL_COUNT))
echo "ì¦ê°€ëŸ‰: ${DIFF}"

if [ "$DIFF" -eq 1 ]; then
  echo "âœ… ì¥ì•  ë³µêµ¬ í›„ ë°ì´í„° ë™ê¸°í™” ì„±ê³µ"
else
  echo "âŒ ë°ì´í„° ë™ê¸°í™” ì‹¤íŒ¨"
fi
```

#### ì˜ˆìƒ ê²°ê³¼
```
âœ… Flink Job ì •ìƒ ì¬ì‹œì‘ë¨
âœ… Checkpointì—ì„œ ë³µêµ¬ë¨
âœ… ì¦ê°€ëŸ‰: 1
âœ… ì¥ì•  ë³µêµ¬ í›„ ë°ì´í„° ë™ê¸°í™” ì„±ê³µ
```

## ğŸ“Š ì„±ëŠ¥ ë©”íŠ¸ë¦­ ìˆ˜ì§‘

### Flink ë©”íŠ¸ë¦­ í™•ì¸
```bash
# Flink Web UI ì ‘ì†
open http://localhost:8081

# í™•ì¸ í•­ëª©:
# - Records Sent (Kafkaë¡œ ì „ì†¡)
# - Records Received (Kafkaì—ì„œ ìˆ˜ì‹ )
# - Backpressure (ì—­ì•• ìƒíƒœ)
# - Checkpoint Duration (ì²´í¬í¬ì¸íŠ¸ ì‹œê°„)
```

### Kafka Consumer Lag í™•ì¸
```bash
docker exec -it kafka kafka-consumer-groups --describe \
  --bootstrap-server localhost:9092 \
  --group flink-sync-connector

# ì¶œë ¥ ì˜ˆì‹œ:
# TOPIC              PARTITION  CURRENT-OFFSET  LOG-END-OFFSET  LAG
# orders-cdc-topic   0          1500            1500            0
# orders-cdc-topic   1          1500            1500            0
# orders-cdc-topic   2          1500            1500            0

# âœ… LAG = 0 (ì´ìƒì )
# âš ï¸ LAG > 100 (ì²˜ë¦¬ ì§€ì—°)
```

### ClickHouse ì¿¼ë¦¬ ì„±ëŠ¥
```sql
-- ì¿¼ë¦¬ ì‹¤í–‰ ì‹œê°„ ì¸¡ì •
SELECT
    toDate(created_at) AS date,
    count() AS orders,
    sum(total_price) AS revenue
FROM order_analytics.orders_realtime
WHERE created_at >= now() - INTERVAL 7 DAY
  AND operation_type != 'DELETE'
GROUP BY date
ORDER BY date DESC;

-- ì‹¤í–‰ ì‹œê°„ í™•ì¸
-- âœ… < 100ms (ìµœì )
-- âš ï¸ 100-500ms (ë³´í†µ)
-- âŒ > 500ms (ìµœì í™” í•„ìš”)
```

## ğŸ” ë°ì´í„° ì •í•©ì„± ê²€ì¦

### ìë™í™” ìŠ¤í¬ë¦½íŠ¸
```bash
cat > validate_data_consistency.sh << 'EOF'
#!/bin/bash

echo "=========================================="
echo "ë°ì´í„° ì •í•©ì„± ê²€ì¦ ì‹œì‘"
echo "=========================================="

# 1. MySQL ì „ì²´ ì¹´ìš´íŠ¸
MYSQL_TOTAL=$(docker exec -it mysql mysql -u root -proot_password order_db \
  -se "SELECT COUNT(*) FROM orders")

# 2. ClickHouse ì „ì²´ ì¹´ìš´íŠ¸ (DELETE ì œì™¸)
CH_TOTAL=$(docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT COUNT(*) FROM order_analytics.orders_realtime WHERE operation_type != 'DELETE'")

echo "MySQL ì „ì²´ ë ˆì½”ë“œ: ${MYSQL_TOTAL}"
echo "ClickHouse ì „ì²´ ë ˆì½”ë“œ: ${CH_TOTAL}"

# 3. ì°¨ì´ ê³„ì‚°
DIFF=$((MYSQL_TOTAL - CH_TOTAL))

if [ "$DIFF" -eq 0 ]; then
  echo "âœ… ë°ì´í„° ì •í•©ì„± ê²€ì¦ ì„±ê³µ"
  exit 0
elif [ "$DIFF" -le 10 ]; then
  echo "âš ï¸ ê²½ë¯¸í•œ ë¶ˆì¼ì¹˜ (${DIFF}ê±´) - íŒŒì´í”„ë¼ì¸ ì§€ì—° ê°€ëŠ¥ì„±"
  exit 1
else
  echo "âŒ ì‹¬ê°í•œ ë¶ˆì¼ì¹˜ (${DIFF}ê±´) - ì¡°ì‚¬ í•„ìš”"
  exit 2
fi
EOF

chmod +x validate_data_consistency.sh
./validate_data_consistency.sh
```

## ğŸš¨ íŠ¸ëŸ¬ë¸”ìŠˆíŒ…

### ë¬¸ì œ 1: ClickHouseì— ë°ì´í„° ë¯¸ë™ê¸°í™”
```bash
# 1. Flink CDC Job ìƒíƒœ í™•ì¸
docker exec -it flink-jobmanager flink list

# 2. Kafka Topic ë©”ì‹œì§€ í™•ì¸
docker exec -it kafka kafka-console-consumer \
  --bootstrap-server localhost:9092 \
  --topic orders-cdc-topic \
  --from-beginning \
  --max-messages 1

# 3. Flink Sync Job ë¡œê·¸ í™•ì¸
docker logs flink-taskmanager | grep ERROR

# 4. ClickHouse ì—°ê²° í…ŒìŠ¤íŠ¸
docker exec -it clickhouse-server clickhouse-client --query "SELECT 1"
```

### ë¬¸ì œ 2: Consumer Lag ì¦ê°€
```bash
# 1. Lag í™•ì¸
docker exec -it kafka kafka-consumer-groups --describe \
  --bootstrap-server localhost:9092 \
  --group flink-sync-connector

# 2. ì›ì¸ ë¶„ì„
# - ClickHouse INSERT ì†ë„ < Kafka Produce ì†ë„
# - Flink Sync Batch í¬ê¸° ë„ˆë¬´ ì‘ìŒ
# - TaskManager ë¦¬ì†ŒìŠ¤ ë¶€ì¡±

# 3. í•´ê²° ë°©ë²•
# - Batch í¬ê¸° ì¦ê°€ (1000 â†’ 5000)
# - Batch Interval ì¦ê°€ (5ì´ˆ â†’ 10ì´ˆ)
# - TaskManager ë³‘ë ¬ë„ ì¦ê°€
```

### ë¬¸ì œ 3: ë°ì´í„° ì¤‘ë³µ
```bash
# 1. ì¤‘ë³µ í™•ì¸
docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT order_id, COUNT(*) AS cnt FROM order_analytics.orders_realtime GROUP BY order_id HAVING cnt > 1"

# 2. ê°•ì œ ì¤‘ë³µ ì œê±° (ReplacingMergeTree)
docker exec -it clickhouse-server clickhouse-client \
  --query "OPTIMIZE TABLE order_analytics.orders_realtime FINAL"

# 3. ìµœì‹  ë ˆì½”ë“œë§Œ ì¡°íšŒ
docker exec -it clickhouse-server clickhouse-client \
  --query "SELECT * FROM order_analytics.orders_realtime FINAL WHERE order_id = 1001"
```

## ğŸ“ˆ ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ (MVP í™˜ê²½)

### ì„±ëŠ¥ ëª©í‘œ
| ë©”íŠ¸ë¦­ | ëª©í‘œ | ì‹¤ì¸¡ |
|--------|------|------|
| End-to-End ì§€ì—° | < 5ì´ˆ | 2-5ì´ˆ |
| ì²˜ë¦¬ëŸ‰ | 100-1,000 TPS | 100-500 TPS |
| ë°ì´í„° ì •í•©ì„± | 100% | 99.9%+ |
| Consumer Lag | < 100 | 0-50 |
| ClickHouse ì¿¼ë¦¬ | < 100ms | 50-100ms |

## ğŸ”„ ì§€ì†ì  ëª¨ë‹ˆí„°ë§

### Cron Job ì„¤ì • (ì„ íƒì )
```bash
# ë§¤ 5ë¶„ë§ˆë‹¤ ë°ì´í„° ì •í•©ì„± ê²€ì¦
*/5 * * * * /path/to/validate_data_consistency.sh >> /var/log/data-validation.log 2>&1

# ë§¤ 10ë¶„ë§ˆë‹¤ Consumer Lag í™•ì¸
*/10 * * * * docker exec kafka kafka-consumer-groups --describe --bootstrap-server localhost:9092 --group flink-sync-connector >> /var/log/kafka-lag.log 2>&1
```

## ğŸ“š ë‹¤ìŒ ë‹¨ê³„
- [í”„ë¡œë•ì…˜ ë°°í¬ ê°€ì´ë“œ](../infrastructure/production-deployment.md)
- [ì„±ëŠ¥ ìµœì í™” ê°€ì´ë“œ](../infrastructure/performance-tuning.md)
- [ì¥ì•  ëŒ€ì‘ ë§¤ë‰´ì–¼](../infrastructure/incident-response.md)
