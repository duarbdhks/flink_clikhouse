package com.flink.sync.job;

import com.flink.sync.config.KafkaSourceConfig;
import com.flink.sync.function.DeduplicationFunction;
import com.flink.sync.sink.ClickHouseSink;
import com.flink.sync.transform.CDCEventTransformer;
import com.flink.sync.transform.ClickHouseRow;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.restartstrategy.RestartStrategies;
import org.apache.flink.api.common.time.Time;
import org.apache.flink.connector.kafka.source.KafkaSource;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.CheckpointConfig;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Objects;
import java.util.concurrent.TimeUnit;

/**
 * Kafka to ClickHouse Sync Job - Kafka CDC ì´ë²¤íŠ¸ë¥¼ ClickHouseë¡œ ë™ê¸°í™”
 * ë°ì´í„° íë¦„:
 * Kafka Topic (orders-cdc) -> Flink CDC Event Transformer -> ClickHouse Sink
 * ì‹¤í–‰ ë°©ë²•:
 * flink run -c com.flink.sync.job.KafkaToClickHouseJob flink-sync-job.jar
 */
public class KafkaToClickHouseJob {

    private static final Logger LOG = LoggerFactory.getLogger(KafkaToClickHouseJob.class);

    public static void main(String[] args) throws Exception {
        // 1. Flink ì‹¤í–‰ í™˜ê²½ ì„¤ì •
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // 2. Checkpoint ì„¤ì • (Exactly-Once ë³´ì¥)
        configureCheckpointing(env);

        // 3. ì¬ì‹œì‘ ì „ëµ ì„¤ì •
        configureRestartStrategy(env);

        // 4. ë³‘ë ¬ë„ ì„¤ì •
        env.setParallelism(2);

        // 5. Kafka Source ìƒì„±
        KafkaSource<String> kafkaSource = KafkaSourceConfig.createOrdersSource();
        LOG.info("âœ… Kafka Source ìƒì„± ì™„ë£Œ");

        // 6. Kafka ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±
        DataStream<String> cdcEventStream = env
                .fromSource(kafkaSource, WatermarkStrategy.noWatermarks(), "Kafka CDC Source")
                .uid("kafka-cdc-source")
                .name("Kafka CDC Event Reader");

        // 7. CDC ì´ë²¤íŠ¸ë¥¼ ClickHouse Rowë¡œ ë³€í™˜
        DataStream<ClickHouseRow> clickHouseRowStream = cdcEventStream
                .map(new CDCEventTransformer())
                .uid("cdc-transformer")
                .name("CDC Event Transformer")
                .filter(Objects::nonNull)  // null í•„í„°ë§ (ë³€í™˜ ì‹¤íŒ¨ ì´ë²¤íŠ¸ ì œì™¸)
                .uid("filter-null-rows")
                .name("Filter Null Rows");

        // 8. ì¤‘ë³µ ì œê±° (Deduplication) - ClickHouse ì‚½ì… ì „ ì• í”Œë¦¬ì¼€ì´ì…˜ ë ˆë²¨ í•„í„°ë§
        DataStream<ClickHouseRow> deduplicatedStream = clickHouseRowStream
                .keyBy(row -> row.getId() + "_" + row.getCdcTsMs()) // (id, cdc_ts_ms) ì¡°í•©ìœ¼ë¡œ ê·¸ë£¹í™”
                .process(new DeduplicationFunction(60)) // 60ì´ˆ State TTL
                .uid("deduplication")
                .name("Deduplication Filter");

        // 9. ClickHouse Sink ìƒì„± ë° ë°ì´í„° ì‚½ì…
        deduplicatedStream
                .addSink(ClickHouseSink.createOrdersSink())
                .uid("clickhouse-sink")
                .name("ClickHouse Orders Sink");

        LOG.info("âœ… ClickHouse Sink ìƒì„± ì™„ë£Œ (ì¤‘ë³µ ì œê±° í™œì„±í™”)");

        // 10. Job ì‹¤í–‰
        LOG.info("ğŸš€ Kafka to ClickHouse Sync Job ì‹œì‘...");
        LOG.info("ğŸ“¥ Source: Kafka (orders-cdc)");
        LOG.info("ğŸ“¤ Sink: ClickHouse (orders_realtime)");
        LOG.info("âš™ï¸  Parallelism: {}", env.getParallelism());
        LOG.info("ğŸ”„ Batch Size: 1000 rows, Interval: 5 seconds");

        env.execute("Kafka CDC to ClickHouse - Orders Sync");
    }

    /**
     * Checkpoint ì„¤ì • (Exactly-Once ë³´ì¥)
     */
    private static void configureCheckpointing(StreamExecutionEnvironment env) {
        // Checkpoint ê°„ê²©: 60ì´ˆ
        env.enableCheckpointing(60000L);

        CheckpointConfig checkpointConfig = env.getCheckpointConfig();

        // Checkpoint ëª¨ë“œ: EXACTLY_ONCE
        checkpointConfig.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

        // Checkpoint ê°„ ìµœì†Œ ê°„ê²©: 30ì´ˆ
        checkpointConfig.setMinPauseBetweenCheckpoints(30000L);

        // Checkpoint íƒ€ì„ì•„ì›ƒ: 10ë¶„
        checkpointConfig.setCheckpointTimeout(600000L);

        // ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ Checkpoint ìˆ˜: 1
        checkpointConfig.setMaxConcurrentCheckpoints(1);

        // Job ì·¨ì†Œ ì‹œì—ë„ Checkpoint ë³´ì¡´
        checkpointConfig.setExternalizedCheckpointCleanup(
                CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION
        );

        // í—ˆìš© ê°€ëŠ¥í•œ Checkpoint ì‹¤íŒ¨ íšŸìˆ˜: 3íšŒ
        checkpointConfig.setTolerableCheckpointFailureNumber(3);

        // Checkpoint ìŠ¤í† ë¦¬ì§€ ì„¤ì •: íŒŒì¼ ì‹œìŠ¤í…œ ê¸°ë°˜ (Job ì¬ì‹œì‘ ì‹œ ë³µêµ¬ ê°€ëŠ¥)
        // Docker ë³¼ë¥¨: ./docker/volumes/flink-checkpoints:/tmp/flink-checkpoints
        checkpointConfig.setCheckpointStorage("file:///tmp/flink-checkpoints");

        LOG.info("âœ… Checkpoint ì„¤ì • ì™„ë£Œ: interval=60s, mode=EXACTLY_ONCE, storage=file:///tmp/flink-checkpoints");
    }

    /**
     * ì¬ì‹œì‘ ì „ëµ ì„¤ì • (ì¥ì•  ë³µêµ¬)
     */
    private static void configureRestartStrategy(StreamExecutionEnvironment env) {
        // ê³ ì • ì§€ì—° ì¬ì‹œì‘ ì „ëµ: ìµœëŒ€ 3íšŒ, 10ì´ˆ ê°„ê²©
        env.setRestartStrategy(
                RestartStrategies.fixedDelayRestart(
                        3, // ìµœëŒ€ ì¬ì‹œì‘ íšŸìˆ˜
                        Time.of(10, TimeUnit.SECONDS) // ì¬ì‹œì‘ ê°„ê²©
                )
        );

        LOG.info("âœ… Restart Strategy ì„¤ì • ì™„ë£Œ: ìµœëŒ€ 3íšŒ, 10ì´ˆ ê°„ê²©");
    }
}
