package com.flink.sync.job;

import com.flink.sync.config.KafkaSourceConfig;
import com.flink.sync.function.DeduplicationFunction;
import com.flink.sync.function.OrderItemsDeduplicationFunction;
import com.flink.sync.sink.ClickHouseSink;
import com.flink.sync.transform.CDCEventTransformer;
import com.flink.sync.transform.ClickHouseRow;
import com.flink.sync.transform.OrderItemsTransformer;
import com.flink.sync.transform.OrderItemsRow;
import org.apache.flink.api.common.eventtime.WatermarkStrategy;
import org.apache.flink.api.common.typeinfo.TypeInformation;
import org.apache.flink.api.common.restartstrategy.RestartStrategies;
import org.apache.flink.api.common.time.Time;
import org.apache.flink.connector.kafka.source.KafkaSource;
import org.apache.flink.streaming.api.CheckpointingMode;
import org.apache.flink.streaming.api.datastream.DataStream;
import org.apache.flink.streaming.api.environment.CheckpointConfig;
import org.apache.flink.streaming.api.environment.StreamExecutionEnvironment;
import org.slf4j.Logger;
import org.slf4j.LoggerFactory;

import java.util.Objects;
import java.util.concurrent.TimeUnit;

/**
 * Kafka to ClickHouse Sync Job - Kafka CDC ì´ë²¤íŠ¸ë¥¼ ClickHouseë¡œ ë™ê¸°í™”
 * ë°ì´í„° íë¦„:
 * 1. Kafka Topic (orders-cdc) -> Flink CDC Event Transformer -> ClickHouse orders_realtime
 * 2. Kafka Topic (order-items-cdc) -> Flink CDC Event Transformer -> ClickHouse order_items_realtime
 * ì‹¤í–‰ ë°©ë²•:
 * flink run -c com.flink.sync.job.KafkaToClickHouseJob flink-sync-job.jar
 */
public class KafkaToClickHouseJob {

    private static final Logger LOG = LoggerFactory.getLogger(KafkaToClickHouseJob.class);

    public static void main(String[] args) throws Exception {
        // 1. Flink ì‹¤í–‰ í™˜ê²½ ì„¤ì •
        final StreamExecutionEnvironment env = StreamExecutionEnvironment.getExecutionEnvironment();

        // 2. Checkpoint ì„¤ì • (Exactly-Once ë³´ì¥)
        configureCheckpointing(env);

        // 3. ì¬ì‹œì‘ ì „ëµ ì„¤ì •
        configureRestartStrategy(env);

        // 4. ë³‘ë ¬ë„ ì„¤ì •
        env.setParallelism(2);

        // ========================================
        // Pipeline 1: Orders (orders-cdc â†’ orders_realtime)
        // ========================================

        // 5-1. Orders Kafka Source ìƒì„±
        KafkaSource<String> ordersKafkaSource = KafkaSourceConfig.createOrdersSource();
        LOG.info("âœ… Orders Kafka Source ìƒì„± ì™„ë£Œ");

        // 6-1. Orders Kafka ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±
        DataStream<String> ordersCdcEventStream = env
                .fromSource(ordersKafkaSource, WatermarkStrategy.noWatermarks(), "Kafka CDC Source - Orders")
                .uid("kafka-cdc-source-orders")
                .name("Kafka CDC Event Reader - Orders");

        // 7-1. Orders CDC ì´ë²¤íŠ¸ë¥¼ ClickHouse Rowë¡œ ë³€í™˜
        DataStream<ClickHouseRow> ordersClickHouseRowStream = ordersCdcEventStream
                .map(new CDCEventTransformer())
                .uid("cdc-transformer-orders")
                .name("CDC Event Transformer - Orders")
                .filter(Objects::nonNull)  // null í•„í„°ë§ (ë³€í™˜ ì‹¤íŒ¨ ì´ë²¤íŠ¸ ì œì™¸)
                .uid("filter-null-rows-orders")
                .name("Filter Null Rows - Orders");

        // 8-1. Orders ì¤‘ë³µ ì œê±° (Deduplication)
        DataStream<ClickHouseRow> ordersDeduplicatedStream = ordersClickHouseRowStream
                .keyBy(row -> String.valueOf(row.getId()))
                .process(new DeduplicationFunction(600)) // 600ì´ˆ (10ë¶„) State TTL
                .uid("deduplication-orders")
                .name("Deduplication Filter - Orders");

        // 9-1. Orders ClickHouse Sink
        ordersDeduplicatedStream
                .addSink(ClickHouseSink.createOrdersSink())
                .uid("clickhouse-sink-orders")
                .name("ClickHouse Orders Sink");

        LOG.info("âœ… Orders Pipeline ìƒì„± ì™„ë£Œ (ì¤‘ë³µ ì œê±° í™œì„±í™”: State TTL 600ì´ˆ)");

        // ========================================
        // Pipeline 2: OrderItems (order-items-cdc â†’ order_items_realtime)
        // ========================================

        // 5-2. OrderItems Kafka Source ìƒì„±
        KafkaSource<String> orderItemsKafkaSource = KafkaSourceConfig.createOrderItemsSource();
        LOG.info("âœ… OrderItems Kafka Source ìƒì„± ì™„ë£Œ");

        // 6-2. OrderItems Kafka ì´ë²¤íŠ¸ ìŠ¤íŠ¸ë¦¼ ìƒì„±
        DataStream<String> orderItemsCdcEventStream = env
                .fromSource(orderItemsKafkaSource, WatermarkStrategy.noWatermarks(), "Kafka CDC Source - OrderItems")
                .uid("kafka-cdc-source-order-items")
                .name("Kafka CDC Event Reader - OrderItems");

        // 7-2. OrderItems CDC ì´ë²¤íŠ¸ë¥¼ ClickHouse Rowë¡œ ë³€í™˜
        DataStream<OrderItemsRow> orderItemsClickHouseRowStream = orderItemsCdcEventStream
                .map(new OrderItemsTransformer())
                .uid("cdc-transformer-order-items")
                .name("CDC Event Transformer - OrderItems")
                .filter(Objects::nonNull)  // null í•„í„°ë§ (ë³€í™˜ ì‹¤íŒ¨ ì´ë²¤íŠ¸ ì œì™¸)
                .uid("filter-null-rows-order-items")
                .name("Filter Null Rows - OrderItems");

        // 8-2. OrderItems ì¤‘ë³µ ì œê±° (Deduplication)
        DataStream<OrderItemsRow> orderItemsDeduplicatedStream = orderItemsClickHouseRowStream
                .keyBy(row -> String.valueOf(row.getId()))
                .process(new OrderItemsDeduplicationFunction(600)) // 600ì´ˆ (10ë¶„) State TTL
                .uid("deduplication-order-items")
                .name("Deduplication Filter - OrderItems");

        // 9-2. OrderItems ClickHouse Sink
        orderItemsDeduplicatedStream
                .addSink(ClickHouseSink.createOrderItemsSink())
                .uid("clickhouse-sink-order-items")
                .name("ClickHouse OrderItems Sink");

        LOG.info("âœ… OrderItems Pipeline ìƒì„± ì™„ë£Œ (ì¤‘ë³µ ì œê±° í™œì„±í™”: State TTL 600ì´ˆ)");

        // 10. Job ì‹¤í–‰
        LOG.info("ğŸš€ Kafka to ClickHouse Sync Job ì‹œì‘...");
        LOG.info("ğŸ“¥ Source 1: Kafka (orders-cdc) â†’ ClickHouse (orders_realtime)");
        LOG.info("ğŸ“¥ Source 2: Kafka (order-items-cdc) â†’ ClickHouse (order_items_realtime)");
        LOG.info("âš™ï¸  Parallelism: {}", env.getParallelism());
        LOG.info("ğŸ”„ Batch Size: 1000 rows, Interval: 5 seconds");

        env.execute("Kafka CDC to ClickHouse - Orders + OrderItems Sync");
    }

    /**
     * Checkpoint ì„¤ì • (Exactly-Once ë³´ì¥)
     */
    private static void configureCheckpointing(StreamExecutionEnvironment env) {
        // Checkpoint ê°„ê²©: 30ì´ˆ (Production í‘œì¤€: ì¥ì•  ë³µêµ¬ ì‹œ ë°ì´í„° ì†ì‹¤ ì°½ ìµœì†Œí™”)
        env.enableCheckpointing(30000L);

        CheckpointConfig checkpointConfig = env.getCheckpointConfig();

        // Checkpoint ëª¨ë“œ: EXACTLY_ONCE
        checkpointConfig.setCheckpointingMode(CheckpointingMode.EXACTLY_ONCE);

        // Checkpoint ê°„ ìµœì†Œ ê°„ê²©: 15ì´ˆ
        checkpointConfig.setMinPauseBetweenCheckpoints(15000L);

        // Checkpoint íƒ€ì„ì•„ì›ƒ: 10ë¶„
        checkpointConfig.setCheckpointTimeout(600000L);

        // ë™ì‹œ ì‹¤í–‰ ê°€ëŠ¥í•œ Checkpoint ìˆ˜: 1
        checkpointConfig.setMaxConcurrentCheckpoints(1);

        // Job ì·¨ì†Œ ì‹œì—ë„ Checkpoint ë³´ì¡´
        checkpointConfig.setExternalizedCheckpointCleanup(
                CheckpointConfig.ExternalizedCheckpointCleanup.RETAIN_ON_CANCELLATION
        );

        // í—ˆìš© ê°€ëŠ¥í•œ Checkpoint ì‹¤íŒ¨ íšŸìˆ˜: 3íšŒ
        checkpointConfig.setTolerableCheckpointFailureNumber(3);

        // Checkpoint ìŠ¤í† ë¦¬ì§€ ì„¤ì •: Sync Job ì „ìš© ë””ë ‰í† ë¦¬
        // Docker ë³¼ë¥¨: ./docker/volumes/flink-checkpoints:/tmp/flink-checkpoints
        // Jobë³„ ê²½ë¡œ ë¶„ë¦¬ë¡œ checkpoint í˜¼ìš© ë°©ì§€ (CDCì™€ SyncëŠ” ë‹¤ë¥¸ operator UID ì‚¬ìš©)
        checkpointConfig.setCheckpointStorage("file:///tmp/flink-checkpoints/sync");

        LOG.info("âœ… Checkpoint ì„¤ì • ì™„ë£Œ: interval=30s, minPause=15s, mode=EXACTLY_ONCE, storage=file:///tmp/flink-checkpoints/sync");
    }

    /**
     * ì¬ì‹œì‘ ì „ëµ ì„¤ì • (ì¥ì•  ë³µêµ¬)
     */
    private static void configureRestartStrategy(StreamExecutionEnvironment env) {
        // ê³ ì • ì§€ì—° ì¬ì‹œì‘ ì „ëµ: ìµœëŒ€ 3íšŒ, 10ì´ˆ ê°„ê²©
        env.setRestartStrategy(
                RestartStrategies.fixedDelayRestart(
                        3, // ìµœëŒ€ ì¬ì‹œì‘ íšŸìˆ˜
                        Time.of(10, TimeUnit.SECONDS) // ì¬ì‹œì‘ ê°„ê²©
                )
        );

        LOG.info("âœ… Restart Strategy ì„¤ì • ì™„ë£Œ: ìµœëŒ€ 3íšŒ, 10ì´ˆ ê°„ê²©");
    }
}
